import os
import pickle
import numpy as np
import torch
from typing import Dict, List, Tuple, Optional
from scipy.spatial.transform import Rotation as R


class MotionLoader:
    """
    Motion data loader for PKL files generated by General Motion Retargeting.
    Handles loading, preprocessing, and serving motion reference data for imitation learning.
    """
    
    def __init__(
        self,
        motion_file: str,
        device: str = "cuda:0",
        loop: bool = True,
        motion_time_offset: float = 0.0
    ):
        """
        Initialize motion loader.
        
        Args:
            motion_file: Path to PKL file containing motion data
            device: Device to store tensors on
            loop: Whether to loop the motion when it ends
            motion_time_offset: Time offset to start motion from (seconds)
        """
        self.device = device
        self.loop = loop
        self.motion_time_offset = motion_time_offset
        
        # Load motion data
        self._load_motion_data(motion_file)
        
        # Initialize state tracking
        self.current_frame = 0
        self.motion_time = 0.0
        
    def _load_motion_data(self, motion_file: str):
        """Load and preprocess motion data from PKL file."""
        if not os.path.exists(motion_file):
            raise FileNotFoundError(f"Motion file not found: {motion_file}")
            
        try:
            with open(motion_file, "rb") as f:
                motion_data = pickle.load(f)
        except (ImportError, AttributeError, ModuleNotFoundError) as e:
            # Handle numpy compatibility issues
            if "numpy._core" in str(e) or "numpy" in str(e):
                print(f"Numpy compatibility issue loading {motion_file}, trying fallback method...")
                try:
                    import pickle5 as fallback_pickle
                    with open(motion_file, "rb") as f:
                        motion_data = fallback_pickle.load(f)
                except ImportError:
                    # Try with encoding parameter for older numpy compatibility
                    try:
                        with open(motion_file, "rb") as f:
                            motion_data = pickle.load(f, encoding='latin1')
                    except:
                        print(f"All fallback methods failed for {motion_file}")
                        raise e
            else:
                raise e
            
        # Extract motion components
        self.fps = motion_data["fps"]
        self.dt = 1.0 / self.fps
        self.num_frames = len(motion_data["root_pos"])
        self.motion_duration = self.num_frames / self.fps
        
        # Convert to tensors and move to device
        # Handle both numpy arrays and Python lists for compatibility
        if isinstance(motion_data["root_pos"], list):
            self.root_pos = torch.tensor(motion_data["root_pos"], dtype=torch.float32, device=self.device)
        else:
            self.root_pos = torch.from_numpy(motion_data["root_pos"]).float().to(self.device)
            
        if isinstance(motion_data["root_rot"], list):
            self.root_rot = torch.tensor(motion_data["root_rot"], dtype=torch.float32, device=self.device)
        else:
            self.root_rot = torch.from_numpy(motion_data["root_rot"]).float().to(self.device)
            
        if isinstance(motion_data["dof_pos"], list):
            self.dof_pos = torch.tensor(motion_data["dof_pos"], dtype=torch.float32, device=self.device)
        else:
            self.dof_pos = torch.from_numpy(motion_data["dof_pos"]).float().to(self.device)
        
        # Store body information if available
        if motion_data.get("local_body_pos") is not None:
            self.local_body_pos = torch.from_numpy(motion_data["local_body_pos"]).float().to(self.device)
        else:
            self.local_body_pos = None
            
        self.link_body_list = motion_data.get("link_body_list", [])
        
        # Compute motion statistics for normalization
        self._compute_motion_stats()
        
        # Precompute derivatives for velocity tracking
        self._compute_derivatives()
        
    def _compute_motion_stats(self):
        """Compute motion statistics for normalization and analysis."""
        self.root_pos_mean = torch.mean(self.root_pos, dim=0)
        self.root_pos_std = torch.std(self.root_pos, dim=0)
        self.dof_pos_mean = torch.mean(self.dof_pos, dim=0)
        self.dof_pos_std = torch.std(self.dof_pos, dim=0)
        
        # Compute motion bounds
        self.root_pos_min = torch.min(self.root_pos, dim=0)[0]
        self.root_pos_max = torch.max(self.root_pos, dim=0)[0]
        self.dof_pos_min = torch.min(self.dof_pos, dim=0)[0]
        self.dof_pos_max = torch.max(self.dof_pos, dim=0)[0]
        
    def _compute_derivatives(self):
        """Precompute velocities and accelerations for smooth tracking."""
        # Root velocities (finite differences)
        self.root_vel = torch.zeros_like(self.root_pos)
        self.root_vel[1:] = (self.root_pos[1:] - self.root_pos[:-1]) / self.dt
        self.root_vel[0] = self.root_vel[1]  # Forward difference for first frame
        
        # Root angular velocities (quaternion differences)
        self.root_ang_vel = torch.zeros_like(self.root_pos)
        for i in range(1, self.num_frames):
            q1 = self.root_rot[i-1]  # xyzw
            q2 = self.root_rot[i]    # xyzw
            # Convert to scipy format (wxyz) for computation
            q1_scipy = q1[[3, 0, 1, 2]]
            q2_scipy = q2[[3, 0, 1, 2]]
            
            r1 = R.from_quat(q1_scipy.cpu().numpy())
            r2 = R.from_quat(q2_scipy.cpu().numpy())
            
            # Compute angular velocity
            r_diff = r2 * r1.inv()
            ang_vel = r_diff.as_rotvec() / self.dt
            self.root_ang_vel[i] = torch.from_numpy(ang_vel).to(self.device)
            
        self.root_ang_vel[0] = self.root_ang_vel[1]  # Forward difference for first frame
        
        # DOF velocities
        self.dof_vel = torch.zeros_like(self.dof_pos)
        self.dof_vel[1:] = (self.dof_pos[1:] - self.dof_pos[:-1]) / self.dt
        self.dof_vel[0] = self.dof_vel[1]  # Forward difference for first frame
        
    def get_motion_state(self, time: float) -> Dict[str, torch.Tensor]:
        """
        Get motion state at specified time.
        
        Args:
            time: Time in seconds
            
        Returns:
            Dictionary containing motion state:
            - root_pos: Root position (3,)
            - root_rot: Root rotation quaternion xyzw (4,)
            - root_vel: Root linear velocity (3,)
            - root_ang_vel: Root angular velocity (3,)
            - dof_pos: Joint positions (21,)
            - dof_vel: Joint velocities (21,)
        """
        # Handle time offset
        time = time + self.motion_time_offset
        
        # Handle looping
        if self.loop:
            time = time % self.motion_duration
        else:
            time = min(time, self.motion_duration - self.dt)
            
        # Find frame indices for interpolation
        frame_idx = time * self.fps
        frame_low = int(np.floor(frame_idx))
        frame_high = min(frame_low + 1, self.num_frames - 1)
        blend = frame_idx - frame_low
        
        # Interpolate motion state
        if frame_low == frame_high:
            # No interpolation needed
            return {
                "root_pos": self.root_pos[frame_low].clone(),
                "root_rot": self.root_rot[frame_low].clone(),
                "root_vel": self.root_vel[frame_low].clone(),
                "root_ang_vel": self.root_ang_vel[frame_low].clone(),
                "dof_pos": self.dof_pos[frame_low].clone(),
                "dof_vel": self.dof_vel[frame_low].clone(),
            }
        else:
            # Linear interpolation for positions and velocities
            root_pos = (1 - blend) * self.root_pos[frame_low] + blend * self.root_pos[frame_high]
            root_vel = (1 - blend) * self.root_vel[frame_low] + blend * self.root_vel[frame_high]
            root_ang_vel = (1 - blend) * self.root_ang_vel[frame_low] + blend * self.root_ang_vel[frame_high]
            dof_pos = (1 - blend) * self.dof_pos[frame_low] + blend * self.dof_pos[frame_high]
            dof_vel = (1 - blend) * self.dof_vel[frame_low] + blend * self.dof_vel[frame_high]
            
            # SLERP for quaternions
            q1 = self.root_rot[frame_low]  # xyzw
            q2 = self.root_rot[frame_high]  # xyzw
            
            # Convert to wxyz for slerp
            q1_wxyz = q1[[3, 0, 1, 2]]
            q2_wxyz = q2[[3, 0, 1, 2]]
            
            # Ensure quaternions are in the same hemisphere
            if torch.dot(q1_wxyz, q2_wxyz) < 0:
                q2_wxyz = -q2_wxyz
                
            # SLERP
            dot = torch.dot(q1_wxyz, q2_wxyz)
            dot = torch.clamp(dot, -1.0, 1.0)
            
            if dot > 0.9995:
                # Linear interpolation for very close quaternions
                result = (1 - blend) * q1_wxyz + blend * q2_wxyz
                result = result / torch.norm(result)
            else:
                theta_0 = torch.acos(dot)
                sin_theta_0 = torch.sin(theta_0)
                theta = theta_0 * blend
                sin_theta = torch.sin(theta)
                
                s0 = torch.cos(theta) - dot * sin_theta / sin_theta_0
                s1 = sin_theta / sin_theta_0
                result = s0 * q1_wxyz + s1 * q2_wxyz
                
            # Convert back to xyzw
            root_rot = result[[1, 2, 3, 0]]
            
            return {
                "root_pos": root_pos,
                "root_rot": root_rot,
                "root_vel": root_vel,
                "root_ang_vel": root_ang_vel,
                "dof_pos": dof_pos,
                "dof_vel": dof_vel,
            }
    
    def get_motion_length(self) -> float:
        """Get total motion duration in seconds."""
        return self.motion_duration
        
    def reset(self, time_offset: float = 0.0):
        """Reset motion to beginning with optional time offset."""
        self.motion_time_offset = time_offset
        self.current_frame = 0
        self.motion_time = 0.0


class MotionLibrary:
    """
    Library for managing multiple motion files.
    Supports random sampling and curriculum learning.
    """
    
    def __init__(
        self,
        motion_dir: str,
        device: str = "cuda:0",
        motion_files: Optional[List[str]] = None
    ):
        """
        Initialize motion library.
        
        Args:
            motion_dir: Directory containing PKL motion files
            device: Device for tensors
            motion_files: Specific list of motion files to load (optional)
        """
        self.device = device
        self.motion_dir = motion_dir
        self.motions = {}
        self.motion_names = []
        
        # Load motion files
        if motion_files is None:
            motion_files = [f for f in os.listdir(motion_dir) if f.endswith('.pkl')]
            
        for motion_file in motion_files:
            motion_path = os.path.join(motion_dir, motion_file)
            motion_name = os.path.splitext(motion_file)[0]
            
            try:
                self.motions[motion_name] = MotionLoader(motion_path, device=device)
                self.motion_names.append(motion_name)
                print(f"Loaded motion: {motion_name} ({self.motions[motion_name].motion_duration:.2f}s)")
            except Exception as e:
                print(f"Failed to load motion {motion_file}: {e}")
                
        if not self.motions:
            raise ValueError(f"No valid motion files found in {motion_dir}")
            
        print(f"Motion library initialized with {len(self.motions)} motions")
        
    def sample_motion(self, motion_name: Optional[str] = None) -> MotionLoader:
        """Sample a motion from the library."""
        if motion_name is None:
            motion_name = np.random.choice(self.motion_names)
        elif motion_name not in self.motions:
            raise ValueError(f"Motion {motion_name} not found in library")
            
        return self.motions[motion_name]
        
    def get_motion_names(self) -> List[str]:
        """Get list of available motion names."""
        return self.motion_names.copy()